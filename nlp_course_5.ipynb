{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCI-KIT LEARN!!!\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "      <th>punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  length  punct\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111      9\n",
       "1   ham                      Ok lar... Joking wif u oni...      29      6\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155      6\n",
       "3   ham  U dun say so early hor... U c already then say...      49      6\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61      2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('nlp_course_notes/TextFiles/smsspamcollection.tsv',sep='\\t') # this file is seperated by tabs for each column\n",
    "\n",
    "df.head() # print the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             predicted ham  predicted spam\n",
      "actual ham            1404              44\n",
      "actual spam            219               5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.87      0.97      0.91      1448\n",
      "        spam       0.10      0.02      0.04       224\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      1672\n",
      "   macro avg       0.48      0.50      0.48      1672\n",
      "weighted avg       0.76      0.84      0.80      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "is_empty = df.isnull().sum() # if everything is 0 (false) then there is no missing data\n",
    "\n",
    "label_count = df['label'].value_counts() # number of times each label shows up\n",
    "\n",
    "# X is the features\n",
    "# Y is the labels\n",
    "\n",
    "x = df[['length','punct']]\n",
    "y = df['label']\n",
    "\n",
    "# randomly split the data in a 70:30 ratio\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=42) \n",
    "\n",
    "lr_model = LogisticRegression(solver='lbfgs') # make a logistic regression model (FOR CLASSIFICATION)\n",
    "# solver is just the algorithm it uses for optimizing the model parameters\n",
    "\n",
    "lr_model.fit(x_train,y_train) # train the model with training data\n",
    "\n",
    "predictions = lr_model.predict(x_test) # use the model to make predictions on the test data\n",
    "\n",
    "cm = pd.DataFrame(metrics.confusion_matrix(y_test,predictions),index=['actual ham','actual spam'],columns=['predicted ham','predicted spam']) # print the confusion matrix to evaluate the results\n",
    "print(cm)\n",
    "\n",
    "print(metrics.classification_report(y_test,predictions)) # print the various metrics for accuracy, like recall and precision\n",
    "\n",
    "# the overall syntax for these types of models is: import model, build model, fit model, predict with model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             predicted ham  predicted spam\n",
      "actual ham            1445               3\n",
      "actual spam             10             214\n",
      "['ham']\n",
      "['ham']\n"
     ]
    }
   ],
   "source": [
    "# FEATURE EXTRACTION (TRANSFORMING TEXT INTO VECTORS)\n",
    "\n",
    "df = pd.read_csv('nlp_course_notes/TextFiles/smsspamcollection.tsv',sep='\\t') # this file is seperated by tabs for each column\n",
    "\n",
    "X = df['message']\n",
    "y = df['label']\n",
    "\n",
    "# randomly split the data in a 70:30 ratio\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42) \n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "# first fit the vectorizer to the training data (build the vocabulary and count the number of words)\n",
    "# then transform the text into vectors, based on the count\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer() # convert word count to word frequency and multiply by the inverse document frequency\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts) # tf-idf transformation on the training data\n",
    "\n",
    "vectorizer = TfidfVectorizer() # combine the count vectorizer and tf-idf steps\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train) # vectorize the training data\n",
    "\n",
    "# after vectorizing the training data, make the model\n",
    "\n",
    "clf = LinearSVC() # linear support vector classifier model\n",
    "clf.fit(X_train_tfidf,y_train)\n",
    "\n",
    "# this is a pipeline of steps/actions, which is often used in NLP to make things simpler/repeatable\n",
    "# the first step is the word vectorization, the next step is the model classification\n",
    "# in this way, we don't have to vectorize the training and test data two separate times\n",
    "# this pipeline object is basically like any other scikit-learn model\n",
    "text_clf = Pipeline([('tfidf',TfidfVectorizer()),('clf',LinearSVC())])\n",
    "\n",
    "# Send the training data through the pipeline\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = text_clf.predict(X_test)\n",
    "\n",
    "cm = pd.DataFrame(metrics.confusion_matrix(y_test,predictions),index=['actual ham','actual spam'],columns=['predicted ham','predicted spam']) # print the confusion matrix to evaluate the results\n",
    "print(cm) # we see that the results are much better since we've incorporated the message feature in our predictions\n",
    "\n",
    "# predict a new message as SPAM or HAM\n",
    "test1 = text_clf.predict([\"Hi, how are you doing today?\"])\n",
    "test2 = text_clf.predict([\"Congratulations! You've been selected as a winner for the new iPhone 13!\"])\n",
    "\n",
    "print(test1)\n",
    "print(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA FILTERING / FORMATTING\n",
    "\n",
    "df.dropna(inplace=True) # removes empty rows (rows with missing data)\n",
    "\n",
    "blanks = []\n",
    "\n",
    "# (index, label, review text)\n",
    "for i,lb,rv in df.itertuples():\n",
    "    if rv.isspace(): # if the review is empty whitespace\n",
    "        blanks.append(i) # add the index of these rows to our list\n",
    "\n",
    "df.dropna(blanks,inplace=True) # removes the rows with reviews that just have whitespaces"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bf2ab4710bb88b95cde5549200cc7126844ad4b46382c8d084742582274cbd47"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('nlp_course': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
